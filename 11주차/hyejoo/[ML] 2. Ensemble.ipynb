{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66ec6f1e",
   "metadata": {},
   "source": [
    "#  2. Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9984e9aa",
   "metadata": {},
   "source": [
    "1. 앙상블이란\n",
    "\n",
    "여러 개의 알고리즘을 결합하여 보다 정확한 예측을 도출\n",
    "\n",
    "하나의 강한 예측기보다는 복수의 약한 예측기 (Weak learner)의 결합이 강하다는 생각에 기반을 둠 (집단지성)\n",
    "\n",
    "비정형 데이터보다는 정형 데이터 분석에서 성과를 보임\n",
    "\n",
    "2. 유형\n",
    "\n",
    " - Voting\n",
    " - Bagging : Random Forest\n",
    " - Boosting\n",
    " - Stacking 등\n",
    " \n",
    "3. 앙상블의 목표  \n",
    "여러 모델들을 활용한 예측 시, 모델 예측의 편향 및 분산을 줄이는 것을 목표로 함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da2a41d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 설정\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sklearn as sk\n",
    "import statsmodels.api as sm\n",
    "import scipy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68845d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib 사용 시 한글 깨짐 문제 해결\n",
    "from matplotlib import font_manager, rc\n",
    "\n",
    "font_path = \"C:/Windows/Fonts/NGULIM.ttf\"\n",
    "font = font_manager.FontProperties(fname = font_path).get_name()\n",
    "rc('font', family = font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d04f142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경고 메시지 비활성화\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40881d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsc\\Desktop\\ADP\n"
     ]
    }
   ],
   "source": [
    "# 경로 확인\n",
    "path = os.getcwd()\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238a3b6e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## 2-1. Voting Classifier\n",
    "\n",
    "1. Hard Voting (다수결 원칙)  \n",
    "\n",
    "2. Soft Voting (클래스 결정 확률 예측치 평균으로 최종 값 예측)\n",
    " - 서로 다른 종류의 모델들을 결합함.\n",
    " - 일반적으로 Soft Voting 성능이 더 좋음.  \n",
    " - Soft Voting의 경우 모델의 가중치에 변화를 줄 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95627418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aa4691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38a35d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>0.07613</td>\n",
       "      <td>...</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.05742</td>\n",
       "      <td>...</td>\n",
       "      <td>22.88</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.07451</td>\n",
       "      <td>...</td>\n",
       "      <td>17.06</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.07389</td>\n",
       "      <td>...</td>\n",
       "      <td>15.49</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.08243</td>\n",
       "      <td>...</td>\n",
       "      <td>15.09</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "5        12.45         15.70           82.57      477.1          0.12780   \n",
       "6        18.25         19.98          119.60     1040.0          0.09463   \n",
       "7        13.71         20.83           90.20      577.9          0.11890   \n",
       "8        13.00         21.82           87.50      519.8          0.12730   \n",
       "9        12.46         24.04           83.97      475.9          0.11860   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760         0.30010              0.14710         0.2419   \n",
       "1           0.07864         0.08690              0.07017         0.1812   \n",
       "2           0.15990         0.19740              0.12790         0.2069   \n",
       "3           0.28390         0.24140              0.10520         0.2597   \n",
       "4           0.13280         0.19800              0.10430         0.1809   \n",
       "5           0.17000         0.15780              0.08089         0.2087   \n",
       "6           0.10900         0.11270              0.07400         0.1794   \n",
       "7           0.16450         0.09366              0.05985         0.2196   \n",
       "8           0.19320         0.18590              0.09353         0.2350   \n",
       "9           0.23960         0.22730              0.08543         0.2030   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "5                 0.07613  ...         15.47          23.75           103.40   \n",
       "6                 0.05742  ...         22.88          27.66           153.20   \n",
       "7                 0.07451  ...         17.06          28.14           110.60   \n",
       "8                 0.07389  ...         15.49          30.73           106.20   \n",
       "9                 0.08243  ...         15.09          40.68            97.65   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "5       741.6            0.1791             0.5249           0.5355   \n",
       "6      1606.0            0.1442             0.2576           0.3784   \n",
       "7       897.0            0.1654             0.3682           0.2678   \n",
       "8       739.3            0.1703             0.5401           0.5390   \n",
       "9       711.4            0.1853             1.0580           1.1050   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "5                0.1741          0.3985                  0.12440  \n",
       "6                0.1932          0.3063                  0.08368  \n",
       "7                0.1556          0.3196                  0.11510  \n",
       "8                0.2060          0.4378                  0.10720  \n",
       "9                0.2210          0.4366                  0.20750  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x = pd.DataFrame(cancer.data, columns = cancer.feature_names)\n",
    "df_x.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8cc659a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "5      0\n",
       "6      0\n",
       "7      0\n",
       "8      0\n",
       "9      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y = pd.DataFrame(cancer.target, columns = ['class'])\n",
    "df_y.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4571e26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff2ed280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.5 KB\n"
     ]
    }
   ],
   "source": [
    "df_x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "442ba96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_x 결측치 없음 ;  0\n",
      "df_y 결측치 없음 ;  0\n"
     ]
    }
   ],
   "source": [
    "print(\"df_x 결측치 없음 ; \", df_x.isnull().sum().sum())\n",
    "print(\"df_y 결측치 없음 ; \", df_y.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aef1ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst radius  \\\n",
       "count     569.000000              569.000000  ...    569.000000   \n",
       "mean        0.181162                0.062798  ...     16.269190   \n",
       "std         0.027414                0.007060  ...      4.833242   \n",
       "min         0.106000                0.049960  ...      7.930000   \n",
       "25%         0.161900                0.057700  ...     13.010000   \n",
       "50%         0.179200                0.061540  ...     14.970000   \n",
       "75%         0.195700                0.066120  ...     18.790000   \n",
       "max         0.304000                0.097440  ...     36.040000   \n",
       "\n",
       "       worst texture  worst perimeter   worst area  worst smoothness  \\\n",
       "count     569.000000       569.000000   569.000000        569.000000   \n",
       "mean       25.677223       107.261213   880.583128          0.132369   \n",
       "std         6.146258        33.602542   569.356993          0.022832   \n",
       "min        12.020000        50.410000   185.200000          0.071170   \n",
       "25%        21.080000        84.110000   515.300000          0.116600   \n",
       "50%        25.410000        97.660000   686.500000          0.131300   \n",
       "75%        29.720000       125.400000  1084.000000          0.146000   \n",
       "max        49.540000       251.200000  4254.000000          0.222600   \n",
       "\n",
       "       worst compactness  worst concavity  worst concave points  \\\n",
       "count         569.000000       569.000000            569.000000   \n",
       "mean            0.254265         0.272188              0.114606   \n",
       "std             0.157336         0.208624              0.065732   \n",
       "min             0.027290         0.000000              0.000000   \n",
       "25%             0.147200         0.114500              0.064930   \n",
       "50%             0.211900         0.226700              0.099930   \n",
       "75%             0.339100         0.382900              0.161400   \n",
       "max             1.058000         1.252000              0.291000   \n",
       "\n",
       "       worst symmetry  worst fractal dimension  \n",
       "count      569.000000               569.000000  \n",
       "mean         0.290076                 0.083946  \n",
       "std          0.061867                 0.018061  \n",
       "min          0.156500                 0.055040  \n",
       "25%          0.250400                 0.071460  \n",
       "50%          0.282200                 0.080040  \n",
       "75%          0.317900                 0.092080  \n",
       "max          0.663800                 0.207500  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa00ae15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "1        357\n",
       "0        212\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.value_counts()\n",
    "  # Description(DESCR)에 따르면 Class 0는 Malignant(악성), Class 1은 Benign(양성)임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac2e548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 나누기\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size = 0.2, random_state = 156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dec11c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting 적용 모델 1 : Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "knn = KNeighborsClassifier(n_neighbors = 8)\n",
    "\n",
    "# Soft Voting 기반의 Ensemble\n",
    "voting = VotingClassifier(estimators = [('LogisiticRegression', logreg), ('KNN', knn)], voting = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2e60adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Voting Classifier :  0.9474\n"
     ]
    }
   ],
   "source": [
    "# 앙상블 모델 성능 평가\n",
    "voting.fit(x_train, y_train)\n",
    "pred = voting.predict(x_test)\n",
    "print('Accuracy of Voting Classifier : {0: .4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9109dae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  LogisticRegression  :  0.9386\n",
      "Accuracy of  KNeighborsClassifier  :  0.9386\n"
     ]
    }
   ],
   "source": [
    "# 개별 모델 성능 평가\n",
    "models = [logreg, knn]\n",
    "\n",
    "for model in models :\n",
    "  model.fit(x_train, y_train)\n",
    "\n",
    "  pred = model.predict(x_test)\n",
    "\n",
    "  class_name = model.__class__.__name__\n",
    "\n",
    "  print('Accuracy of ', class_name, ' : {0: .4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55967f1a",
   "metadata": {},
   "source": [
    "## 2-2. Bagging (Boostrap Aggregating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b9c83a",
   "metadata": {},
   "source": [
    "### 2-2-1. Bootstrap\n",
    "\n",
    "표본으로부터 반복복원추출하는 방법으로 Resampling(재표집)하여 계산한 표본통계량을 기반으로 모수의 분포를 추정한다.\n",
    "\n",
    " - 본래의 모집단이 iid assumption (Independent and Identical Distribution)을 충족해야 한다.\n",
    " - Resampling 횟수가 적을 경우 Outlier의 영향을 받을 수 있다.\n",
    " - 정규성 가정이 필요하지 않다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34d91fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모집단 평균 :  50.2698\n",
      "모집단 표준편차 :  28.786681086224583\n"
     ]
    }
   ],
   "source": [
    "pop_list = np.random.randint(1, 100, size = 10000)\n",
    "\n",
    "print(\"모집단 평균 : \", np.mean(pop_list))\n",
    "print(\"모집단 표준편차 : \", np.std(pop_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4326fa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_list_array = np.array(pop_list, int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58d32284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0010462667640176448\n"
     ]
    }
   ],
   "source": [
    "# scipy를 이용한 Bootstrapping\n",
    "import scipy.stats as stats\n",
    "\n",
    "result = stats.bootstrap((pop_list_array, ), np.std, confidence_level = 0.95)\n",
    "print(result.bootstrap_distribution.mean() - np.std(pop_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f17b3795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 회 반복 : 28.73642105317586\n",
      "100 회 실시 시 모집단과의 차이 :  0.05026003304872262\n",
      "\n",
      "\n",
      "500 회 반복 : 28.5896016423374\n",
      "500 회 실시 시 모집단과의 차이 :  0.19707944388718346\n",
      "\n",
      "\n",
      "1000 회 반복 : 28.585695150662488\n",
      "1000 회 실시 시 모집단과의 차이 :  0.20098593556209465\n",
      "\n",
      "\n",
      "5000 회 반복 : 28.6229174401168\n",
      "5000 회 실시 시 모집단과의 차이 :  0.16376364610778182\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sampling_hj(lst) : \n",
    "    sample_idx = np.random.permutation(len(lst))\n",
    "    sample_idx = sample_idx[ : int(round(len(lst) * 0.01, 0))]\n",
    "    sample_list = [lst[idx] for idx in sample_idx]\n",
    "    \n",
    "    return sample_list\n",
    "\n",
    "def bootstrap_hj(lst, repetition_size) :\n",
    "    \n",
    "    sample_std_list = []\n",
    "    \n",
    "    for i in range(repetition_size) : \n",
    "        sample_list = sampling_hj(lst)\n",
    "        \n",
    "        sample_std_list.append(np.std(sample_list))\n",
    "    \n",
    "    print(repetition_size, \"회 반복 :\", np.mean(sample_std_list))\n",
    "    \n",
    "    return np.mean(sample_std_list)\n",
    "\n",
    "\n",
    "for i in [100, 500, 1000, 5000] :\n",
    "    result = bootstrap_hj(pop_list, i)\n",
    "    \n",
    "    print(i, \"회 실시 시 모집단과의 차이 : \", np.abs(np.std(pop_list) - result))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ffb487",
   "metadata": {},
   "source": [
    "### 2-2-2. Out-of-Bag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de40f40",
   "metadata": {},
   "source": [
    "Bootstrap의 복원추출으로 뽑히지 않은 데이터들을 활용하여 모델의 성능을 측정한다.\n",
    "\n",
    "보통 전체 데이터의 $ 2 \\over 3 $ (약 63% 가량) 정도가 추출된다고 하며, 나머지 추출되지 않은  $ 1 \\over 3 $ 가량의 관측치들을 $ OOB \\; Observation $이라 하며, Validation Set처럼 취급한다.\n",
    "\n",
    "\n",
    "Ex) Bootstrap 실행횟수 : $ B = 9 $\n",
    "\n",
    "Observation $ x_i $가 추출에서 제외된 개별 모델들 (전체 $ B $ 개 중 약 $ \\frac{B}{3}개 $)의 $ x_i $에 대한 예측치의 평균을 내어 OOB MSE나 Classification Error를 구하여 성능 측정을 함으로써 Cross Validation을 대체할 수 있다. (단, Cross Validation이 보통 더 낫다고 한다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1163d300",
   "metadata": {},
   "source": [
    "[참고] Out-of-Bag 실행 시 평균 샘플링 비율 산출\n",
    "\n",
    "$m $개의 Sample에서 무작위하게 한 개만 추출할 때, sample $ x_i $가 추출되거나 추출에서 제외될 확률은 다음과 같다.\n",
    "\n",
    "$$ P(sample \\; x_i \\; is \\; selected) = \\frac{1}{m} $$\n",
    "\n",
    "$$ P(sample \\; x_i \\; is \\; not \\; selected) = 1 - \\frac{1}{m} $$\n",
    "\n",
    "무작위 복원 추출을 $ m $번 진행할 시, $m$회 모두 선택되지 않을 확률은\n",
    "\n",
    "$$ P(sample \\; x_i \\; is \\; not \\; selected \\; for \\; m \\; times) = (1 - \\frac{1}{m})^m $$\n",
    "\n",
    "로피탈의 정리를 이용하여 확률을 계산해보자.\n",
    "\n",
    "$$ \\lim_{m \\leftarrow \\infty}(1 - \\frac{1}{m})^m = y $$\n",
    "\n",
    "$$ \\ln y = \\lim_{m \\leftarrow \\infty} m \\ln \\; (1 - \\frac{1}{m}) = \\lim_{x \\leftarrow 0} \\frac{\\ln \\; (1 - x)}{x} $$\n",
    "\n",
    "$$ = \\lim_{x \\leftarrow 0} \\frac{\\frac{d}{dx} \\ln \\; (1 - x)}{\\frac{d}{dx} x} = \\lim_{x \\leftarrow 0} \\frac{- 1}{1 - x} = -1$$\n",
    "\n",
    "$$ y = e^{-1} = 0.3678... $$\n",
    "\n",
    "$$ 1 - y = 1 - e^{-1} \\approx 0.63212 $$\n",
    "\n",
    "$ \\therefore $ Sample $ x_i $가 최소 1회 이상 추출될 확률은 약 36.8%이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03b2d2f",
   "metadata": {},
   "source": [
    "### 2-2-3. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cccbadb",
   "metadata": {},
   "source": [
    "Bootstrap을 활용하여 개별 트리 모델 생성. \n",
    "이 때, Pruning (가지치기)을 하지 않는다.\n",
    "High Variance 문제점이 있던 Deicision Tree를 Bootstrap으로 B개 생성하여 최종적으로 평균을 냄으로써 Variance를 줄여준다.\n",
    "\n",
    "다만, 유사한 Training Set을 사용하였기 때문에 개별 모델 간 독립성이 보장되지 않는다. \n",
    "\n",
    "이를 극복하기 위하여 Random Forest는 Feature Selection 과정을 거쳐 모델 간 Correlation을 낮추어 성능을 개선하였다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28b22363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cb642d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris_x = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
    "iris_y = pd.DataFrame(iris.target, columns = [\"species\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e467f86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in iris_y['species'].unique() :\n",
    "    iris_y['species'].replace(i, iris.target_names[i], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd763552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris_x_train, iris_x_test, iris_y_train, iris_y_test = train_test_split(iris_x, iris_y, test_size = 0.25, stratify = iris.target, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f02e9e",
   "metadata": {},
   "source": [
    "#### 2-2-3-1. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cff14451",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators = 500\n",
    "                                 # n_estimators : Tree의 수 (OR Bootstrap 반복 횟수)\n",
    "                            , criterion = 'entropy'\n",
    "                            , max_depth = 3\n",
    "                            , max_features = 'sqrt'\n",
    "                                 # max_features : Best Split을 위한 Feature 갯수. 'sqrt'이면 sqrt(n_features)이다.\n",
    "                            , bootstrap = True\n",
    "                            , max_samples = 1.0\n",
    "                                # max_samples : 'bootstrap = True'일 때의 resampling size (int이면 개수, float이면 비율)\n",
    "                            , oob_score = True\n",
    "                                # oob_score : \n",
    "                            , random_state = 123\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13cc25dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=3, max_samples=1.0,\n",
       "                       n_estimators=500, oob_score=True, random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=3, max_samples=1.0,\n",
       "                       n_estimators=500, oob_score=True, random_state=123)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=3, max_samples=1.0,\n",
       "                       n_estimators=500, oob_score=True, random_state=123)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(iris_x_train, iris_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ccfd063",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_y_pred = rfc.predict(iris_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c63e34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-Bag Score Estimate :  0.964\n",
      "Mean Accuracy Score :  0.974\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(iris_y_test, iris_y_pred)\n",
    "\n",
    "print(f\"Out-of-Bag Score Estimate : {rfc.oob_score_ : .3}\")\n",
    "print(f\"Mean Accuracy Score : {accuracy : .3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74aa2f2",
   "metadata": {},
   "source": [
    "OOB Score과 Accuracy는 높게 나오나,  \n",
    "모든 Class를 고르게 잘 분류하는지 확인해볼 필요가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "564da6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(iris_y_test, iris_y_pred), index = iris.target_names, columns = iris.target_names)\n",
    "sns.heatmap(cm, annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1193effd",
   "metadata": {},
   "source": [
    "#### 2-2-3-2. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2b15458",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = pd.read_csv(\"./boston_housing.csv\", engine = 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a17c930",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.drop(['CAT. MEDV'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb4510ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        B  LSTAT  MEDV  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad267625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    int64  \n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    int64  \n",
      " 9   TAX      506 non-null    int64  \n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  MEDV     506 non-null    float64\n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "boston.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e3f2b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_x = boston.drop('MEDV', axis = 1)\n",
    "boston_y = boston['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "824057c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_x_train, boston_x_test, boston_y_train, boston_y_test = train_test_split(boston_x, boston_y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e0145ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=4, max_features=0.3, max_samples=1.0,\n",
       "                      oob_score=True, random_state=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=4, max_features=0.3, max_samples=1.0,\n",
       "                      oob_score=True, random_state=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=4, max_features=0.3, max_samples=1.0,\n",
       "                      oob_score=True, random_state=100)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators = 100\n",
    "                           , criterion = 'squared_error'\n",
    "                           , max_depth = 4\n",
    "                           , max_features = 0.3\n",
    "                           , max_samples = 1.0\n",
    "                           , bootstrap = True\n",
    "                           , oob_score = True\n",
    "                           , random_state = 100)\n",
    "\n",
    "rfr.fit(boston_x_train, boston_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "190714b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-Bag :  0.786\n"
     ]
    }
   ],
   "source": [
    "boston_pred = rfr.predict(boston_x_test)\n",
    "\n",
    "print('Out-of-Bag : ', round(rfr.oob_score_, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eee8f90",
   "metadata": {},
   "source": [
    "## 2-3. Boosting  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea743d07",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88c5d3cc",
   "metadata": {},
   "source": [
    "$$ H(x) = sign\\{\\sum_{m = 1}^M a_m h_m(x)\\} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd43511",
   "metadata": {},
   "source": [
    "## 2-4. Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1e7b21",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7fbfc9d",
   "metadata": {},
   "source": [
    "## 2-5. 의문점 : Ensemble은 항상 정답일까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d477f4",
   "metadata": {},
   "source": [
    "앙상블 기법의 전제 : 개별 모델 예측의 Bias (편향) & Variance (분산)를 줄여, 성능을 향상시킨다.\n",
    "\n",
    "→ 만약 예측 성능이 향상되지 않았다면, 다음 두 가지 경우로 나누어 볼 수 있다.\n",
    "\n",
    "① 개별 모델 예측 결과의 편향, 분산 차이가 유의미하지 않은 경우\n",
    "\n",
    " - 앙상블 적용 전후 예측 결과의 편향 및 분산 차이가 크려면 모델들의 상관관계가 낮아야 한다. → 모델 간 Correlation이 낮은 조합으로 구성해야 함\n",
    "\n",
    "② 앙상블 후 편향과 분산이 줄었으나, 성능 향상으로 이어지지 않은 경우\n",
    "\n",
    " - 개별 모델 성능 기준 조합이 좋은 결과를 담보하지는 않는다.\n",
    " - 중간 정도의 성능을 내는 모델들의 조합도 고려할 것."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f1a8d8",
   "metadata": {},
   "source": [
    "### 2-5-1. 그렇다면 조합을 어떻게 구성해야 할까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42900d30",
   "metadata": {},
   "source": [
    "#### Rule 1. Base Learner의 정확도\n",
    "\n",
    "[Assumption]  Binary Classification (Binomial Distribution)\n",
    "\n",
    "$$ P(Correct) = p $$\n",
    "$$ Number \\; of \\; Correctly \\; Classifying \\;Learner = k $$\n",
    "\n",
    "앙상블 모델의 정확도(이항분포 기댓값)는 다음과 같다.\n",
    "\n",
    "$$ P_{emsemble}(K;L, p) = {L \\choose K} p^k (1-p)^{(L-K)} $$\n",
    "\n",
    "Case 1. $ p $ 가 $ \\frac{1}{2} $ 이하면서 $ L $ 이 증가하면 앙상블 모델의 예측 정확도가 하락한다.\n",
    "\n",
    "Case 2. $ p $ 가 $ \\frac{1}{2} $ 이상이고 $ L $ 이 증가하면 앙상블 모델의 예측 정확도가 상승한다.\n",
    "\n",
    "→ 앙상블 모델에 쓰일 Base Learner의 정확도는 최소 0.5 이상이어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a8ecd8",
   "metadata": {},
   "source": [
    "#### Rule 2. Base Learner 간의 상관성 (Correlation)\n",
    "\n",
    "\n",
    "$$ Var(X + Y) = Var(X) + Var(Y) + 2 Cov(X, Y) $$\n",
    "\n",
    "$$ X, Y : Base \\; Learner $$ \n",
    "$$ X + Y : Ensemble \\; of \\; Base \\; Learner \\; X \\; and \\; Y $$\n",
    "\n",
    "만약 X와 Y가 독립이 아니라면 공분산 $ Cov(X, Y) > 0 $ 이 되어 앙상블의 분산이 증가하여 성능이 오히려 하락할 수 있다.\n",
    "\n",
    "→ 앙상블 모델에 쓰일 Base Learner들은 각각 독립이어야 한다.\n",
    "\n",
    "\n",
    "[참고] Base Learner의 수를 확장하였을 때의 수식\n",
    "\n",
    "$$ Var \\, (\\frac{Z_1 + ... + Z_n}{n}) = \\frac{1}{n^2}{Var(Z_1) + Var(Z_2) + ... + \\sum \\sum Cov(Z_i, Z_j)} $$\n",
    "\n",
    "$$ = \\frac{1}{n^2}{n\\sigma^2 + \\sum \\sum Cov(Z_i, Z_j)} $$\n",
    "\n",
    "$$ = \\frac{\\sigma^2}{n} + \\frac{1}{n^2} {\\sum \\sum Cov(Z_i, Z_j)}$$\n",
    "\n",
    "\n",
    "$$ Z_i : Base \\; Learner (i = 1, 2, ... , n) $$ \n",
    "$$ \\sum_{i = 1} {Z_i} : Ensemble \\; of \\; Base \\; Learner \\; X \\; and \\; Y $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12a4378",
   "metadata": {},
   "source": [
    "#### Rule 3. Base Learner의 수\n",
    "\n",
    "이론적으로 무한대의 Base Learner를 결합시킬 수 있음.  \n",
    "그러나, Computation Cost 등의 현실적 한계로 인하여 실제로는 불가하다.\n",
    "\n",
    "중심극한정리에 따라 Base Learner가 최소 30개 이상이면 좋은 성능을 낼 가능성이 있다고 판단할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b64a55",
   "metadata": {},
   "source": [
    "참고\n",
    "\n",
    "https://velog.io/@jaylnne/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%95%99%EC%83%81%EB%B8%94-Ensemble-%EC%9D%80-%ED%95%AD%EC%83%81-%EB%AA%A8%EB%8D%B8%EC%9D%98-%EC%84%B1%EB%8A%A5%EC%9D%84-%ED%96%A5%EC%83%81%EC%8B%9C%ED%82%AC%EA%B9%8C  \n",
    "\n",
    "https://todayisbetterthanyesterday.tistory.com/47"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
